{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "code-lab-2-pcam-curaeaidlhw.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BkD49fyXpBS",
        "colab_type": "text"
      },
      "source": [
        "Code Lab 2: PatchCamelyon (PCAM) Histopathological Cancer Detection \n",
        "==="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSIhkEIAXpBU",
        "colab_type": "text"
      },
      "source": [
        "## The Problem\n",
        "PCam an image classification dataset based off of one of the Camelyon16 tasks where 96x96, 3-color channel image patches are extracted from whole-slide images (WSI).  These slides were extracted from histopathologic scans of lymph node sections in order to determine if the lymph nodes contain metastases (cancer cells).  From the Camelyon16 web page:\n",
        ">  This task has a high clinical relevance but requires large amounts of reading time from pathologists. Therefore, a successful solution would hold great promise to reduce the workload of the pathologists while at the same time reduce the subjectivity in diagnosis. [1](https://camelyon16.grand-challenge.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2od3AEmXpBU",
        "colab_type": "text"
      },
      "source": [
        "![pcam-cover](https://github.com/basveeling/pcam/raw/master/pcam.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7HO2m4wXpBV",
        "colab_type": "text"
      },
      "source": [
        "In this lab, we will explore transfer learning and explainable AI (XAI) techniques on the PCam dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCX8fuojXpBV",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK_QRV8PXpBW",
        "colab_type": "text"
      },
      "source": [
        "We will start off using a similar setup to Code Lab 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vxuvYYpXpBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvo-719kXpBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNyu9vyaXpBb",
        "colab_type": "text"
      },
      "source": [
        "We will continue to use the Eager Execution API for Tensorflow 1.13.  Let us make sure that it is enabled and that the GPU is visible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1uHmvKXXpBb",
        "colab_type": "code",
        "colab": {},
        "outputId": "0831b53f-8c68-46e1-b374-e6e9670988b8"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "print('Tensorflow version: ',tf.__version__)\n",
        "print('Is GPU available: %s' % str(tf.test.is_gpu_available()))\n",
        "print('Is Eager Execution enabled?: %s' % str(tf.executing_eagerly()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  1.13.1\n",
            "Is GPU available: False\n",
            "Is Eager Execution enabled?: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLpvgBiTXpBf",
        "colab_type": "text"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhTvhxOXpBf",
        "colab_type": "text"
      },
      "source": [
        "### About Pcam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DriuGwJYXpBg",
        "colab_type": "text"
      },
      "source": [
        "PCam is contained in three data splits:\n",
        "    1. Training: 262K samples\n",
        "    2. Validation: 33K\n",
        "    3. Testing: 33K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FKVGHHxXpBg",
        "colab_type": "text"
      },
      "source": [
        "The patches are labeled 'positive' for containing a metastases if there was at least one pixel of segment in the central 32x32 region of the patch from the segmentation of the WSI that the patch was extracted from.  The dataset was constructed to be evenly balanced with 50/50 'present'/'not present'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgC_P_joXpBh",
        "colab_type": "text"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grx-qwj2XpBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import boto3\n",
        "import os\n",
        "\n",
        "s3 = boto3.client('s3',\n",
        "endpoint_url = 'https://s3.wasabisys.com',\n",
        "aws_access_key_id = 'VM2WCNG36U812Y1NGCT3',\n",
        "aws_secret_access_key='g3Dqovv3IYlIFDZyNWONXZSU5yhGZvWhKOJrBQRI')\n",
        "\n",
        "def download_files(filenames, save_dir):\n",
        "    for i, filename in enumerate(filenames):\n",
        "         print('Downloading %d: %s' % (i, filename)) \n",
        "         download_file(filename, save_dir)\n",
        "\n",
        "def download_file(filename, save_dir):\n",
        "    full_filename = os.path.join(save_dir,filename)\n",
        "    if os.path.exists(full_filename):\n",
        "        print('\\tAlready have: %s' % full_filename)\n",
        "        return\n",
        "    s3.download_file('curaedlhw',filename,full_filename)\n",
        "    print('\\tCOMPLETE: %s saved to %s' % (filename, save_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO_33VClYm82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c07fd6bc-cb78-4c74-ae21-654261a339a5"
      },
      "source": [
        "datasets = {\n",
        "    'train' : {\n",
        "        'x': 'camelyonpatch_level_2_split_train_x.h5.gz',\n",
        "        'y': 'camelyonpatch_level_2_split_train_y.h5.gz',\n",
        "        'meta': 'camelyonpatch_level_2_split_train_meta.csv'\n",
        "    },\n",
        "    'val' : {\n",
        "        'x': 'camelyonpatch_level_2_split_valid_x.h5.gz',\n",
        "        'y': 'camelyonpatch_level_2_split_valid_y.h5.gz',\n",
        "        'meta': 'camelyonpatch_level_2_split_valid_meta.csv'\n",
        "    },\n",
        "    'test' : {\n",
        "        'x': 'camelyonpatch_level_2_split_test_x.h5.gz',\n",
        "        'y': 'camelyonpatch_level_2_split_test_y.h5.gz',\n",
        "        'meta': 'camelyonpatch_level_2_split_test_meta.csv'\n",
        "    }\n",
        "}\n",
        "FILELIST = []\n",
        "for scenario in datasets.values():\n",
        "  for filename in scenario.values():\n",
        "    FILELIST.append('data/' + filename)\n",
        "print(FILELIST)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data/camelyonpatch_level_2_split_train_x.h5.gz', 'data/camelyonpatch_level_2_split_train_y.h5.gz', 'data/camelyonpatch_level_2_split_train_meta.csv', 'data/camelyonpatch_level_2_split_valid_x.h5.gz', 'data/camelyonpatch_level_2_split_valid_y.h5.gz', 'data/camelyonpatch_level_2_split_valid_meta.csv', 'data/camelyonpatch_level_2_split_test_x.h5.gz', 'data/camelyonpatch_level_2_split_test_y.h5.gz', 'data/camelyonpatch_level_2_split_test_meta.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUYSABpgYOAh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c75f4294-2d29-4d1a-a74e-df1864b83f85"
      },
      "source": [
        "IS_ONEPANEL = False\n",
        "NEED_DOWNLOAD = True\n",
        "if IS_ONEPANEL:\n",
        "    DATA_DIR='/onepanel/input/datasets/curae/skin-cancer-mnist/1'\n",
        "else:\n",
        "    import os\n",
        "    # import load_data\n",
        "#     DATA_DIR = '/storage/codelab1'\n",
        "    DATA_DIR = 'data'\n",
        "    if NEED_DOWNLOAD:\n",
        "        # if not os.path.exists(DATA_DIR):\n",
        "        #     os.mkdir(DATA_DIR)\n",
        "        download_files(FILELIST,'')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 0: data/camelyonpatch_level_2_split_train_x.h5.gz\n",
            "\tAlready have: data/camelyonpatch_level_2_split_train_x.h5.gz\n",
            "Downloading 1: data/camelyonpatch_level_2_split_train_y.h5.gz\n",
            "\tAlready have: data/camelyonpatch_level_2_split_train_y.h5.gz\n",
            "Downloading 2: data/camelyonpatch_level_2_split_train_meta.csv\n",
            "\tAlready have: data/camelyonpatch_level_2_split_train_meta.csv\n",
            "Downloading 3: data/camelyonpatch_level_2_split_valid_x.h5.gz\n",
            "\tCOMPLETE: data/camelyonpatch_level_2_split_valid_x.h5.gz saved to \n",
            "Downloading 4: data/camelyonpatch_level_2_split_valid_y.h5.gz\n",
            "\tCOMPLETE: data/camelyonpatch_level_2_split_valid_y.h5.gz saved to \n",
            "Downloading 5: data/camelyonpatch_level_2_split_valid_meta.csv\n",
            "\tCOMPLETE: data/camelyonpatch_level_2_split_valid_meta.csv saved to \n",
            "Downloading 6: data/camelyonpatch_level_2_split_test_x.h5.gz\n",
            "\tCOMPLETE: data/camelyonpatch_level_2_split_test_x.h5.gz saved to \n",
            "Downloading 7: data/camelyonpatch_level_2_split_test_y.h5.gz\n",
            "\tCOMPLETE: data/camelyonpatch_level_2_split_test_y.h5.gz saved to \n",
            "Downloading 8: data/camelyonpatch_level_2_split_test_meta.csv\n",
            "\tCOMPLETE: data/camelyonpatch_level_2_split_test_meta.csv saved to \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln_MJfFvclm_",
        "colab_type": "text"
      },
      "source": [
        "The x and y files are compressed are so we need to extract them to local."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDOcd82dabbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import shutil\n",
        "for filename in FILELIST:\n",
        "  with gzip.open(filename, 'rb') as f_in:\n",
        "      filename2 = '.'.join(filename.split('.')[:-1])\n",
        "      with open(filename2, 'wb') as f_out:\n",
        "          print('Extracing %s' % filename2)\n",
        "          shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V5qCpGpdNQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}